# Architecture

This document covers design decisions, the data ingestion pipeline, coupon validation internals, error flows, and common developer tasks. For quick start and API reference, see [README.md](./README.md).

## Design Decisions

### PostgreSQL over SQLite

PostgreSQL supports concurrent writes, NUMERIC types for precise decimal math, and shared state for horizontal scaling. The `pgx/v5` driver with `pgxpool` provides connection pooling suitable for production workloads.

### shopspring/decimal for monetary math

All pricing and discount calculations use `decimal.Decimal` instead of `float64`. This eliminates rounding errors that are common with IEEE 754 floating-point arithmetic in financial contexts. Values are stored as `NUMERIC(10,2)` in PostgreSQL.

### 2-pass bloom filter for coupon ingestion

Instead of loading all ~313M codes into memory (which would require tens of gigabytes), the pipeline uses bloom filters at ~170MB each. Two passes over the data identify codes appearing in 2+ files with high confidence. The 0.1% false positive rate is acceptable because the candidate set is tiny (8 codes out of 313M).

### Clean architecture with domain layer

Domain types, interfaces, and business logic live under `internal/domain/` with no imports from generated code (`gen/oas`). The storage layer imports domain (correct dependency direction). HTTP handlers are thin: they convert OAS types to domain types, call the domain service, and map results back. This keeps business logic testable without HTTP or database concerns.

### Single server with push telemetry

A single HTTP server on `:8080` serves both the API and health probes (`/livez`, `/readyz`). Metrics, traces, and profiles are pushed to their respective backends (Prometheus via OTLP, Tempo via OTLP, Pyroscope) rather than pulled, eliminating the need for a second internal server.

### ogen code generation

The HTTP layer is generated by ogen from the OpenAPI 3.1 spec (`api/openapi.yaml`). ogen generates the router, request/response codecs, validation, and OpenTelemetry instrumentation. This provides compile-time type safety, eliminates hand-written boilerplate, and keeps the API contract in sync with the spec.

### Why plain pgx instead of sqlc

Nine queries. The overhead of a codegen step and double-mapping (pgx row -> sqlc struct -> domain struct) wasn't paying for itself. With plain pgx we scan directly into domain types, SQL lives next to the code that uses it, and there's one less tool in the build chain.

### Graceful shutdown sequence

The shutdown follows a Kubernetes-friendly pattern:

1. Readiness probe returns unhealthy (`SetReady(false)`)
2. Wait for configured delay (default 3s) to allow load balancers to drain
3. Shut down the HTTP server with a timeout (default 15s)
4. Stop health check background goroutines

## Data Ingestion Pipeline

The `cmd/coupon-ingest` tool processes three gzip-compressed files (each ~100M+ codes) to find coupon codes that appear in two or more files.

### Algorithm: 2-Pass Bloom Filter

**Pass 1 -- Build bloom filters (concurrent):**

For each of the 3 files, a bloom filter is built in parallel. Each filter holds ~120M entries at a 0.1% false positive rate, consuming approximately 170MB of memory.

**Pass 2 -- Find candidates (concurrent):**

Each file is streamed again. For every code, the pipeline checks whether it exists in any *other* file's bloom filter. Candidates are tracked with a bitmask indicating which files contain them.

**Validation:**

After merging bitmasks from all files, codes with `popcount(bitmask) >= 2` are confirmed valid.

### Performance Characteristics

| Metric         | Value                                     |
|----------------|-------------------------------------------|
| Total codes    | ~313 million across 3 files               |
| Memory         | ~510MB for bloom filters                  |
| Decompression  | `klauspost/pgzip` for parallel gunzip     |
| Concurrency    | Files processed in parallel via `errgroup` |
| Code filtering | Only codes 8-10 chars are considered      |

### Code Length Distribution

Analysis of the input files reveals that valid codes are exactly 8 characters, while the vast majority of noise codes are 9 or 10 characters:

- **File 1**: 107,260,777 codes, all 8 chars
- **File 2**: 107,260,768 codes at 9 chars + 8 codes at 8 chars
- **File 3**: 98,566,144 codes at 10 chars + 8 codes at 8 chars

## Coupon Validation Rules

Validation happens in `internal/domain/coupon/validator.go` (`RepoValidator.Validate`). Checks run in this order:

1. **Lookup** -- `Repository.FindByCode` does a case-insensitive match against active coupons. Returns `ErrInvalidCoupon` if not found.
2. **Temporal validity** -- If `valid_from` is set and `now < valid_from`, or `valid_until` is set and `now > valid_until`, returns `ErrCouponExpired`.
3. **Usage limit** -- If `max_uses > 0` and `uses >= max_uses`, returns `ErrCouponUsageLimitReached`.
4. **Minimum items** -- If `min_items > 0` and `totalQuantity(items) < min_items`, returns `ErrInvalidCoupon`.
5. **Discount calculation** -- Delegates to the appropriate strategy based on `discount_type`.
6. **Max discount cap** -- If `max_discount > 0` and the computed discount exceeds it, clamp to `max_discount`.
7. **Increment uses** -- `Repository.IncrementUses` atomically increments the counter.

### Discount Strategies

Implemented in `internal/domain/coupon/discount.go`:

| Type           | Formula                                       | Notes                              |
|----------------|-----------------------------------------------|------------------------------------|
| `percentage`   | `subtotal * value / 100`                      | Rounded to 2 decimal places        |
| `fixed`        | `min(value, subtotal)`                        | Cannot exceed subtotal             |
| `free_lowest`  | Lowest unit price among cart items            | Ignores quantity; price of 1 unit  |

All amounts are floored at zero (negative discounts impossible) and rounded to 2 decimal places.

## Error Flow

Domain errors are mapped to HTTP responses in `internal/handler/order.go` (`mapOrderError`):

| Domain Error                          | HTTP Status | Message                       |
|---------------------------------------|-------------|-------------------------------|
| `order.ErrEmptyItems`                 | 400         | `items required`              |
| `*order.InvalidQuantityError`         | 422         | `quantity must be greater...` |
| `*order.ProductNotFoundError`         | 422         | `product {id} not found`      |
| `coupon.ErrInvalidCoupon`             | 422         | `invalid coupon code`         |
| `coupon.ErrCouponExpired`             | 422         | `coupon expired`              |
| `coupon.ErrCouponUsageLimitReached`   | 422         | `coupon usage limit reached`  |
| `product.ErrNotFound` (GET endpoint)  | 404         | `product not found`           |
| Any other error                       | 500         | Internal server error         |

## Common Tasks for Developers

### Adding a new coupon condition

1. Add the field to `coupon.Rule` in `internal/domain/coupon/coupon.go`.
2. Add the column to `db/migrations/001_schema.sql` (or a new migration).
3. Update the scan function in `internal/repository/coupon.go` (`scanCouponRule`).
4. Add the validation check in `internal/domain/coupon/validator.go` (between step 3 and step 4 in the validation order above).
5. Write a test in `internal/domain/coupon/validator_test.go`.

### Adding a new API endpoint

1. Define the endpoint in `api/openapi.yaml`.
2. Run `make generate` to regenerate `gen/oas/`.
3. Implement the handler method in `internal/handler/` (it must satisfy the generated interface).
4. Wire any new dependencies in `internal/app/app.go`.

### Adding a new discount type

1. Add a new `DiscountType` constant in `internal/domain/coupon/coupon.go`.
2. Add an `applyNewType` function in `internal/domain/coupon/discount.go`.
3. Add the case to the `switch` in `Apply`.
4. Write tests in `internal/domain/coupon/discount_test.go`.

### Running tests

```bash
make test               # Unit tests with race detector + coverage
make test-integration   # Integration tests (requires Docker)
make lint               # golangci-lint
```
